{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats \n",
    "import seaborn as sns\n",
    "# import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"font\", size=14)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_f = 'limesurvey_feature_results_w_dims.csv'\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(input_f, 'r') as fid:\n",
    "    csv_reader = csv.DictReader(fid, delimiter=',')\n",
    "    fieldnames = csv_reader.fieldnames\n",
    "    for line in csv_reader:\n",
    "        data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = pd.DataFrame(data).iloc[:, 1:].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = initial_df.columns[12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(prefix, df):\n",
    "    df.to_csv(f'korrelatsiooni_csvd/{prefix}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_features(model, dimname):\n",
    "    \n",
    "    print(model.coef_)\n",
    "\n",
    "    feature_importance = abs(model.coef_[0])\n",
    "    \n",
    "    \n",
    "    feature_importance = 1.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "    featfig = plt.figure(figsize=(15,20))\n",
    "    featax = featfig.add_subplot(1, 1, 1)\n",
    "\n",
    "    featax.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "    featax.set_yticks(pos)\n",
    "    featax.set_yticklabels(np.array(X.columns)[sorted_idx], fontsize=10)\n",
    "    featax.set_xlabel(f'Relative Feature Importance {str.upper(dimname)}')\n",
    "\n",
    "    # plt.tight_layout()   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-cliff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_corr_pairs(corr_df):\n",
    "\n",
    "    columns = [line for line in corr_df]\n",
    "    matches = []\n",
    "\n",
    "    for column, rows in corr_df.items():\n",
    "        for m, score in rows.items():\n",
    "            if (score > 0.75 or score < -0.75) and column != m:\n",
    "                matches.append([(column, m), score])\n",
    "            continue\n",
    "\n",
    "    without_duplicates = []\n",
    "    for ws, i in matches:\n",
    "        ls = (sorted(ws), i)\n",
    "        if ls not in without_duplicates:\n",
    "            without_duplicates.append(ls)       \n",
    "\n",
    "    return without_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap(dim, corr_data):\n",
    "\n",
    "    my_colors = ['black', 'lightgrey', 'white', 'red']\n",
    "    my_cmap = ListedColormap(my_colors)\n",
    "    bounds = [-1.0, -0.75, 0.75, 1.0]\n",
    "    my_norm = BoundaryNorm(bounds, ncolors=len(my_colors))\n",
    "\n",
    "\n",
    "\n",
    "    mask = np.triu(np.ones_like(corr_data))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20,20))\n",
    "    hmap = sns.heatmap(corr_data,\n",
    "                yticklabels=1, \n",
    "                ax=ax,\n",
    "                linewidths=1.0,\n",
    "                cmap=my_cmap,\n",
    "                norm=my_norm,\n",
    "                mask=mask,\n",
    "               cbar_kws = dict(use_gridspec=False,location=\"top\")\n",
    "               )\n",
    "\n",
    "    colorbar = ax.collections[0].colorbar\n",
    "    hmap.figure.savefig(f'heatmapid/{dim}_heatmap.png', format='png', dpi=150)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = initial_df.iloc[:, 12:]\n",
    "all_corr = all_df.corr(method='pearson').round(2)\n",
    "\n",
    "save_csv('dimensions', all_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_heatmap('all_dims', all_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = get_corr_pairs(all_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_df(dim_name):\n",
    "    positive = initial_df.loc[initial_df['abs']>=2, initial_df.columns[12:]]\n",
    "    negative = initial_df.loc[initial_df['abs']<2, initial_df.columns[12:]]\n",
    "    \n",
    "    return positive, negative\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-quantum",
   "metadata": {},
   "source": [
    "## ABSTRAKTNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, neg = make_new_df('abs')\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_corr = pos.corr(method='pearson').round(2)\n",
    "save_csv('abs', abs_corr)\n",
    "abs_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_heatmap('abs', abs_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = get_corr_pairs(abs_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-violation",
   "metadata": {},
   "source": [
    "\n",
    "### NORMAALJAOTUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(dim, df1, df2, features):\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(20, 200))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        df1_mean = np.mean(df1[str(feature)])\n",
    "        df1_std = np.std(df1[str(feature)])\n",
    "        pdf1 = stats.norm.pdf(df1[str(feature)].sort_values(), df1_mean, df1_std)\n",
    "        \n",
    "        df2_mean = np.mean(df2[str(feature)])\n",
    "        df2_std = np.std(df2[str(feature)])\n",
    "        pdf2 = stats.norm.pdf(df2[str(feature)].sort_values(), df2_mean, df2_std)\n",
    "    \n",
    "        ax = plt.subplot(40, 2, i+1)\n",
    "        plt.plot(df1[str(feature)].sort_values(), pdf1, label='>=2')\n",
    "        plt.plot(df2[str(feature)].sort_values(), pdf2, label='<2')\n",
    "        plt.legend(loc=1, prop={'size': 20})\n",
    "        plt.xlabel(str(feature.upper()))\n",
    "\n",
    "#         plt.savefig(f'normdist_plots/{dim}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot('abs', pos, neg, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-success",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-forest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-snowboard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-tension",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "technological-commercial",
   "metadata": {},
   "source": [
    "### LOGISTILINE REGRESSIOON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [*feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_abs = initial_df.loc[:, feats + ['abs']].astype('float64')\n",
    "only_abs['state'] = [1 if score >= 1 else 0 for score in only_abs['abs']]\n",
    "# print(only_abs)\n",
    "\n",
    "final_features = only_abs.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = only_abs[final_features]\n",
    "y = only_abs.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "\n",
    "plot_important_features(model, 'abstraktsus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_reg = smf.logit(\"state ~ coref + hapax_legomena + noun + nom_case + avg_word_len + past_tense + pres_tense + obl + adv + num + ade_case + nummod + part_case\", data=only_abs).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-underground",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-mineral",
   "metadata": {},
   "source": [
    "## AFEKTIIVNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'afek'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "afek_pos, afek_neg = make_new_df('afek')\n",
    "\n",
    "\n",
    "print(len(afek_pos), len(afek_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dim_df_corr = pos.corr(method='pearson').round(2)\n",
    "save_csv(dim, dim_df_corr)\n",
    "\n",
    "generate_heatmap(dim, dim_df_corr)\n",
    "\n",
    "\n",
    "pairs = get_corr_pairs(dim_df_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')\n",
    "\n",
    "\n",
    "generate_plot(dim, pos, neg, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['afek']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['afek']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'afektiivsus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ avg_word_len + coref + noun + adv + pron + verbtype_ratio + TTR + punct + active_voice + adj + conj + avr_sent_len\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-location",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "personalized-basket",
   "metadata": {},
   "source": [
    "## AEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'aeg'\n",
    "\n",
    "tugev = len(initial_df.loc[(initial_df[dim] < 3) & (initial_df[dim] > 2), feature_names])\n",
    "moodukas = len(initial_df.loc[(initial_df[dim] < 2) & (initial_df[dim] > 1), feature_names])\n",
    "nork = len(initial_df.loc[initial_df[dim] < 1, feature_names])\n",
    "\n",
    "print(tugev, moodukas, nork)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "aeg_df, aeg_not_df = make_new_df(initial_df, dim, 2)\n",
    "\n",
    "aeg_corr = aeg_df.corr(method='pearson').round(2)\n",
    "save_csv(dim, 'present', aeg_corr)\n",
    "aeg_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(20,20))\n",
    "hmap = sns.heatmap(aeg_corr, linewidths=0.1, ax=ax)\n",
    "save_heatmap(hmap, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot('aeg', aeg_df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['aeg']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['aeg']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'aeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ coref + past_tense + pres_tense + obl + verbtype_ratio + adv + num + avg_word_len + gen_case + nummod + noun + core_verb + ade_case + propn + da_inf + cop\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-ireland",
   "metadata": {},
   "source": [
    "## ARGUMENTATIIVNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'arg'\n",
    "\n",
    "tugev = len(initial_df.loc[(initial_df[dim] < 3) & (initial_df[dim] > 2), feature_names])\n",
    "moodukas = len(initial_df.loc[(initial_df[dim] < 2) & (initial_df[dim] > 1), feature_names])\n",
    "nork = len(initial_df.loc[initial_df[dim] < 1, feature_names])\n",
    "\n",
    "print(tugev, moodukas, nork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_df, arg_not_df = make_new_df(initial_df, dim, 2)\n",
    "\n",
    "arg_corr = arg_df.corr(method='pearson').round(2)\n",
    "save_csv(dim, 'present', arg_corr)\n",
    "arg_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(20,20))\n",
    "hmap = sns.heatmap(arg_corr, linewidths=0.1, ax=ax)\n",
    "save_heatmap(hmap, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot('arg', arg_df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['arg']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['arg']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'arg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ coref + hapax_legomena + propn + verbtype_ratio + past_tense + pres_tense + avg_word_len + gen_case + conj + TTR + adj + neg_polarity + obl + part_case\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-metadata",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-accounting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-enterprise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "literary-longitude",
   "metadata": {},
   "source": [
    "## FORMAALNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'form'\n",
    "\n",
    "tugev = len(initial_df.loc[(initial_df[dim] < 3) & (initial_df[dim] > 2), feature_names])\n",
    "moodukas = len(initial_df.loc[(initial_df[dim] < 2) & (initial_df[dim] > 1), feature_names])\n",
    "nork = len(initial_df.loc[initial_df[dim] < 1, feature_names])\n",
    "\n",
    "print(dim)\n",
    "print(tugev, moodukas, nork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "form_df, form_not_df = make_new_df(initial_df, dim, 2)\n",
    "\n",
    "form_corr = form_df.corr(method='pearson').round(2)\n",
    "save_csv(dim, 'present', form_corr)\n",
    "form_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(20,20))\n",
    "hmap = sns.heatmap(form_corr, linewidths=0.1, ax=ax)\n",
    "save_heatmap(hmap, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot('form', form_df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['form']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['form']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'formaalsus')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_reg = smf.logit(\"state ~ avg_word_len + coref + gen_case + noun + obl + adv + nmod + num\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-nickel",
   "metadata": {},
   "source": [
    "## IMPERSONAALNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'imp'\n",
    "\n",
    "tugev = len(initial_df.loc[(initial_df[dim] < 3) & (initial_df[dim] > 2), feature_names])\n",
    "moodukas = len(initial_df.loc[(initial_df[dim] < 2) & (initial_df[dim] > 1), feature_names])\n",
    "nork = len(initial_df.loc[initial_df[dim] < 1, feature_names])\n",
    "\n",
    "print(dim)\n",
    "print(tugev, moodukas, nork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df, imp_not_df = make_new_df(initial_df, dim, 2)\n",
    "\n",
    "imp_corr = imp_df.corr(method='pearson').round(2)\n",
    "save_csv(dim, 'present', imp_corr)\n",
    "imp_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(20,20))\n",
    "hmap = sns.heatmap(imp_corr, linewidths=0.1, ax=ax)\n",
    "save_heatmap(hmap, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot('imp', imp_df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['imp']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['imp']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'impersonaalsus')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ avg_word_len + coref + noun + past_tense + pres_tense + conj + pron + num\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-excellence",
   "metadata": {},
   "source": [
    "## INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'info'\n",
    "\n",
    "tugev = len(initial_df.loc[(initial_df[dim] < 3) & (initial_df[dim] > 2), feature_names])\n",
    "moodukas = len(initial_df.loc[(initial_df[dim] < 2) & (initial_df[dim] > 1), feature_names])\n",
    "nork = len(initial_df.loc[initial_df[dim] < 1, feature_names])\n",
    "print(dim)\n",
    "print(tugev, moodukas, nork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df, info_not_df = make_new_df(initial_df, dim, 2)\n",
    "\n",
    "info_corr = info_df.corr(method='pearson').round(2)\n",
    "save_csv(dim, 'present', info_corr)\n",
    "info_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(20,20))\n",
    "hmap = sns.heatmap(info_corr, linewidths=0.1, ax=ax)\n",
    "save_heatmap(hmap, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot('info', info_df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['info']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['info']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'info')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_reg = smf.logit(\"state ~ coref + num + avg_word_len + active_voice + propn + nummod + pron + ind_mood + hapax_legomena + nsubj\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-russian",
   "metadata": {},
   "source": [
    "## INSTRUEERIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'inst'\n",
    "\n",
    "tugev = len(initial_df.loc[(initial_df[dim] < 3) & (initial_df[dim] > 2), feature_names])\n",
    "moodukas = len(initial_df.loc[(initial_df[dim] < 2) & (initial_df[dim] > 1), feature_names])\n",
    "nork = len(initial_df.loc[initial_df[dim] < 1, feature_names])\n",
    "\n",
    "print(dim)\n",
    "print(tugev, moodukas, nork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_df, inst_not_df = make_new_df(initial_df, dim, 2)\n",
    "\n",
    "inst_corr = inst_df.corr(method='pearson').round(2)\n",
    "save_csv(dim, 'present', inst_corr)\n",
    "inst_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(20,20))\n",
    "hmap = sns.heatmap(inst_corr, linewidths=0.1, ax=ax)\n",
    "save_heatmap(hmap, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot('inst', inst_df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['inst']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['inst']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'instrueerivus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ coref + pres_tense + nom_case + pron + hapax_legomena + past_tense + verbtype_ratio + noun + third_prs_verb + second_prs_verb + imp_mood + pron\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-thought",
   "metadata": {},
   "source": [
    "## INTERAKTIIVNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'inter'\n",
    "\n",
    "tugev = len(initial_df.loc[(initial_df[dim] < 3) & (initial_df[dim] > 2), feature_names])\n",
    "moodukas = len(initial_df.loc[(initial_df[dim] < 2) & (initial_df[dim] > 1), feature_names])\n",
    "nork = len(initial_df.loc[initial_df[dim] < 1, feature_names])\n",
    "\n",
    "print(dim)\n",
    "print(tugev, moodukas, nork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df, inter_not_df = make_new_df(initial_df, dim, 2)\n",
    "\n",
    "inter_corr = inter_df.corr(method='pearson').round(2)\n",
    "save_csv(dim, 'present', inter_corr)\n",
    "inter_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(20,20))\n",
    "hmap = sns.heatmap(inter_corr, linewidths=0.1, ax=ax)\n",
    "save_heatmap(hmap, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot('inter', inter_df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['inter']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['inter']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'inter')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ avg_word_len + hapax_legomena + TTR + gen_case + noun + verbtype_ratio + avr_sent_len\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-newspaper",
   "metadata": {},
   "source": [
    "## KEER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'keer'\n",
    "\n",
    "tugev = len(initial_df.loc[(initial_df[dim] < 3) & (initial_df[dim] > 2), feature_names])\n",
    "moodukas = len(initial_df.loc[(initial_df[dim] < 2) & (initial_df[dim] > 1), feature_names])\n",
    "nork = len(initial_df.loc[initial_df[dim] < 1, feature_names])\n",
    "\n",
    "print(dim)\n",
    "print(tugev, moodukas, nork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "keer_df, keer_not_df = make_new_df(initial_df, dim, 2)\n",
    "\n",
    "keer_corr = keer_df.corr(method='pearson').round(2)\n",
    "save_csv(dim, 'present', keer_corr)\n",
    "keer_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(20,20))\n",
    "hmap = sns.heatmap(keer_corr, linewidths=0.1, ax=ax)\n",
    "save_heatmap(hmap, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot('keer', keer_df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['keer']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['keer']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'keerulisus')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ avg_word_len + coref + hapax_legomena + verbtype_ratio + abbr + nmod + past_tense + obl + active_voice\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-preliminary",
   "metadata": {},
   "source": [
    "## SPONT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'spont'\n",
    "\n",
    "tugev = len(initial_df.loc[(initial_df[dim] < 3) & (initial_df[dim] > 2), feature_names])\n",
    "moodukas = len(initial_df.loc[(initial_df[dim] < 2) & (initial_df[dim] > 1), feature_names])\n",
    "nork = len(initial_df.loc[initial_df[dim] < 1, feature_names])\n",
    "\n",
    "print(dim)\n",
    "print(tugev, moodukas, nork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "spont_df, spont_not_df = make_new_df(initial_df, dim, 2)\n",
    "\n",
    "spont_corr = spont_df.corr(method='pearson').round(2)\n",
    "save_csv(dim, 'present', spont_corr)\n",
    "spont_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(20,20))\n",
    "hmap = sns.heatmap(spont_corr, linewidths=0.1, ax=ax)\n",
    "save_heatmap(hmap, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot('spont', spont_df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['spont']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['spont']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'spontaansus')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ avg_word_len + coref + noun + gen_case + nom_case + avr_sent_len + obl + propn\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-galaxy",
   "metadata": {},
   "source": [
    "## SUBJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'subj'\n",
    "\n",
    "tugev = len(initial_df.loc[(initial_df[dim] < 3) & (initial_df[dim] > 2), feature_names])\n",
    "moodukas = len(initial_df.loc[(initial_df[dim] < 2) & (initial_df[dim] > 1), feature_names])\n",
    "nork = len(initial_df.loc[initial_df[dim] < 1, feature_names])\n",
    "\n",
    "print(dim)\n",
    "print(tugev, moodukas, nork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_df, subj_not_df = make_new_df(initial_df, dim, 2)\n",
    "\n",
    "subj_corr = aeg_df.corr(method='pearson').round(2)\n",
    "save_csv(dim, 'present', subj_corr)\n",
    "subj_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(20,20))\n",
    "hmap = sns.heatmap(subj_corr, linewidths=0.1, ax=ax)\n",
    "save_heatmap(hmap, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot('subj', subj_df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['subj']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['subj']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'subjektiivsus')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ avg_word_len + coref + verbtype_ratio + adv + propn + noun\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
