{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accomplished-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats \n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "crude-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"font\", size=14)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "universal-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_f = 'limesurvey_feature_results_w_dims_uus.csv'\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(input_f, 'r') as fid:\n",
    "    csv_reader = csv.DictReader(fid, delimiter=',')\n",
    "    fieldnames = csv_reader.fieldnames\n",
    "    for line in csv_reader:\n",
    "        data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spatial-personal",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-94b2f53e2c60>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0minitial_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.virtualenvs/limesurvey/lib/python3.8/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36mastype\u001B[0;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[1;32m   5875\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5876\u001B[0m             \u001B[0;31m# else, only a single dtype is given\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5877\u001B[0;31m             \u001B[0mnew_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_mgr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5878\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_constructor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnew_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__finalize__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"astype\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5879\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/limesurvey/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001B[0m in \u001B[0;36mastype\u001B[0;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[1;32m    629\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbool\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"raise\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    630\u001B[0m     ) -> \"BlockManager\":\n\u001B[0;32m--> 631\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"astype\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    632\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    633\u001B[0m     def convert(\n",
      "\u001B[0;32m~/.virtualenvs/limesurvey/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001B[0m\n\u001B[1;32m    425\u001B[0m                     \u001B[0mapplied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    426\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 427\u001B[0;31m                     \u001B[0mapplied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    428\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mNotImplementedError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    429\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mignore_failures\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/limesurvey/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001B[0m in \u001B[0;36mastype\u001B[0;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[1;32m    671\u001B[0m             \u001B[0mvals1d\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    672\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 673\u001B[0;31m                 \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mastype_nansafe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvals1d\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    674\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mValueError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    675\u001B[0m                 \u001B[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/limesurvey/lib/python3.8/site-packages/pandas/core/dtypes/cast.py\u001B[0m in \u001B[0;36mastype_nansafe\u001B[0;34m(arr, dtype, copy, skipna)\u001B[0m\n\u001B[1;32m   1095\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcopy\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mis_object_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mis_object_dtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1096\u001B[0m         \u001B[0;31m# Explicit copy, or required since NumPy can't view from / to object.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1097\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0marr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1098\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1099\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0marr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "initial_df = pd.DataFrame(data).iloc[:, 1:].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "turkish-occasion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>abs</th>\n",
       "      <th>afek</th>\n",
       "      <th>aeg</th>\n",
       "      <th>arg</th>\n",
       "      <th>form</th>\n",
       "      <th>imp</th>\n",
       "      <th>info</th>\n",
       "      <th>inst</th>\n",
       "      <th>inter</th>\n",
       "      <th>...</th>\n",
       "      <th>appos</th>\n",
       "      <th>nummod</th>\n",
       "      <th>amod</th>\n",
       "      <th>advcl</th>\n",
       "      <th>voc</th>\n",
       "      <th>cop</th>\n",
       "      <th>conj</th>\n",
       "      <th>cc</th>\n",
       "      <th>yneemid</th>\n",
       "      <th>emoticons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arhiiv_koolielu_ee.ela_481254</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041916167664671</td>\n",
       "      <td>0.029940119760479</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035928143712575</td>\n",
       "      <td>0.095808383233533</td>\n",
       "      <td>0.047904191616767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arvamus_postimees_ee.ela_5946</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02013422818792</td>\n",
       "      <td>0.067114093959732</td>\n",
       "      <td>0.023489932885906</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033557046979866</td>\n",
       "      <td>0.033557046979866</td>\n",
       "      <td>0.030201342281879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arvamusaed_ee.ela_274676</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004329004329004</td>\n",
       "      <td>0.034632034632035</td>\n",
       "      <td>0.038961038961039</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012987012987013</td>\n",
       "      <td>0.038961038961039</td>\n",
       "      <td>0.038961038961039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arvamusaed_ee.ela_6007</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020979020979021</td>\n",
       "      <td>0.083916083916084</td>\n",
       "      <td>0.034965034965035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013986013986014</td>\n",
       "      <td>0.034965034965035</td>\n",
       "      <td>0.027972027972028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bhr_balanss_ee.ela_565106</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059782608695652</td>\n",
       "      <td>0.016304347826087</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021739130434783</td>\n",
       "      <td>0.048913043478261</td>\n",
       "      <td>0.032608695652174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>www_vorumaateataja_ee.ela_241120</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040322580645161</td>\n",
       "      <td>0.010752688172043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024193548387097</td>\n",
       "      <td>0.043010752688172</td>\n",
       "      <td>0.043010752688172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>www_vorumaateataja_ee.ela_494965</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02547770700637</td>\n",
       "      <td>0.044585987261147</td>\n",
       "      <td>0.038216560509554</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02547770700637</td>\n",
       "      <td>0.02547770700637</td>\n",
       "      <td>0.02547770700637</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>www_vsport_ee.ela_120496</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>www_xn--eestimngula-q8a_ee.ela_40079</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035087719298246</td>\n",
       "      <td>0.017543859649123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017543859649123</td>\n",
       "      <td>0.105263157894737</td>\n",
       "      <td>0.06140350877193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>ylle_mrt_ee.ela_101705</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.01875</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.05625</td>\n",
       "      <td>0.053125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  file_id   abs  afek   aeg   arg  form   imp  \\\n",
       "0           arhiiv_koolielu_ee.ela_481254  1.35  0.85  0.65  1.55   0.7   1.8   \n",
       "1           arvamus_postimees_ee.ela_5946  0.65  1.15   0.7  0.65  0.45  0.65   \n",
       "2                arvamusaed_ee.ela_274676  1.25  1.65  0.15   1.5  0.15  0.55   \n",
       "3                  arvamusaed_ee.ela_6007   0.6   1.2   0.8  1.85  0.45  1.15   \n",
       "4               bhr_balanss_ee.ela_565106  1.15   0.8   0.4   1.4   0.7  0.75   \n",
       "..                                    ...   ...   ...   ...   ...   ...   ...   \n",
       "115      www_vorumaateataja_ee.ela_241120  0.35  1.25   2.1  0.65  0.15   0.9   \n",
       "116      www_vorumaateataja_ee.ela_494965   0.5   1.4   0.6   1.5  0.55  0.85   \n",
       "117              www_vsport_ee.ela_120496   0.1   0.8   2.6  0.55  0.85  0.95   \n",
       "118  www_xn--eestimngula-q8a_ee.ela_40079   0.4   0.6  0.35   0.5  0.55   1.6   \n",
       "119                ylle_mrt_ee.ela_101705  1.05   2.6  1.25   1.7  0.15   0.7   \n",
       "\n",
       "     info  inst inter  ...              appos             nummod  \\\n",
       "0     1.1   0.9  0.45  ...                  0  0.041916167664671   \n",
       "1    1.15  0.75   0.7  ...   0.02013422818792  0.067114093959732   \n",
       "2    0.35   0.6  0.85  ...  0.004329004329004  0.034632034632035   \n",
       "3    0.65   0.3  0.45  ...  0.020979020979021  0.083916083916084   \n",
       "4    0.85  0.25   0.2  ...                  0  0.059782608695652   \n",
       "..    ...   ...   ...  ...                ...                ...   \n",
       "115   0.7  0.75   1.7  ...                  0  0.040322580645161   \n",
       "116   1.2   0.4  0.55  ...   0.02547770700637  0.044585987261147   \n",
       "117   2.1   0.8  0.65  ...              0.028              0.044   \n",
       "118  1.85  2.65   0.7  ...  0.035087719298246  0.017543859649123   \n",
       "119  0.75   0.5   0.6  ...                  0           0.028125   \n",
       "\n",
       "                  amod advcl                voc                cop  \\\n",
       "0    0.029940119760479     0  0.035928143712575  0.095808383233533   \n",
       "1    0.023489932885906     0  0.033557046979866  0.033557046979866   \n",
       "2    0.038961038961039     0  0.012987012987013  0.038961038961039   \n",
       "3    0.034965034965035     0  0.013986013986014  0.034965034965035   \n",
       "4    0.016304347826087     0  0.021739130434783  0.048913043478261   \n",
       "..                 ...   ...                ...                ...   \n",
       "115  0.010752688172043     0  0.024193548387097  0.043010752688172   \n",
       "116  0.038216560509554     0   0.02547770700637   0.02547770700637   \n",
       "117                  0     0              0.012              0.068   \n",
       "118                  0     0  0.017543859649123  0.105263157894737   \n",
       "119            0.01875     0              0.025            0.05625   \n",
       "\n",
       "                  conj cc yneemid emoticons  \n",
       "0    0.047904191616767  0       0            \n",
       "1    0.030201342281879  0       0            \n",
       "2    0.038961038961039  0       0            \n",
       "3    0.027972027972028  0       0            \n",
       "4    0.032608695652174  0       0            \n",
       "..                 ... ..     ...       ...  \n",
       "115  0.043010752688172  0       0            \n",
       "116   0.02547770700637  0       0            \n",
       "117               0.04  0       0            \n",
       "118   0.06140350877193  0       0            \n",
       "119           0.053125  0       0            \n",
       "\n",
       "[120 rows x 92 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aerial-graduate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['noun', 'adj', 'propn', 'adv', 'intj', 'cconj', 'sconj', 'adp', 'det',\n",
       "       'num', 'punct', 'symbol', 'particle', 'pron', 'abbr', 'TTR',\n",
       "       'avg_word_len', 'avr_sent_len', 'hapax_legomena', 'coref', 'see_pron',\n",
       "       'see_det', '1st_pron', '2nd_pron', '3rd_pron', 'active_voice',\n",
       "       'passive_voice', '1st_prs_verb', '2nd_prs_verb', '3rd_prs_verb',\n",
       "       'core_verb', 'verbtype_ratio', 'da_inf', 'gerund', 'supine',\n",
       "       'verb_particle', 'discourse', 'pres_tense', 'past_tense', 'ind_mood',\n",
       "       'cond_mood', 'imp_mood', 'quot_mood', 'neg_polarity', 'nom_case',\n",
       "       'gen_case', 'part_case', 'ill_case', 'ine_case', 'ela_case',\n",
       "       'alla_case', 'ade_case', 'abl_case', 'tra_case', 'ter_case', 'ess_case',\n",
       "       'abe_case', 'com_case', 'nsubj', 'nsubj_cop', 'modal', 'acl:relc',\n",
       "       'csubj', 'csubj_cop', 'obj', 'ccomp', 'xcomp', 'obl', 'nmod', 'appos',\n",
       "       'nummod', 'amod', 'advcl', 'voc', 'cop', 'conj', 'cc', 'yneemid',\n",
       "       'emoticons'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = initial_df.columns[12:]\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(prefix, df):\n",
    "    df.to_csv(f'korrelatsiooni_csvd/{prefix}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_features(model, dimname):\n",
    "    \n",
    "    print(model.coef_)\n",
    "\n",
    "    feature_importance = abs(model.coef_[0])\n",
    "    \n",
    "    \n",
    "    feature_importance = 1.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "    featfig = plt.figure(figsize=(15,20))\n",
    "    featax = featfig.add_subplot(1, 1, 1)\n",
    "\n",
    "    featax.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "    featax.set_yticks(pos)\n",
    "    featax.set_yticklabels(np.array(X.columns)[sorted_idx], fontsize=10)\n",
    "    featax.set_xlabel(f'Relative Feature Importance {str.upper(dimname)}')\n",
    "\n",
    "    # plt.tight_layout()   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-ordinary",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_corr_pairs(corr_df):\n",
    "\n",
    "    columns = [line for line in corr_df]\n",
    "    matches = []\n",
    "\n",
    "    for column, rows in corr_df.items():\n",
    "        for m, score in rows.items():\n",
    "            if (score > 0.75 or score < -0.75) and column != m:\n",
    "                matches.append([(column, m), score])\n",
    "            continue\n",
    "\n",
    "    without_duplicates = []\n",
    "    for ws, i in matches:\n",
    "        ls = (sorted(ws), i)\n",
    "        if ls not in without_duplicates:\n",
    "            without_duplicates.append(ls)       \n",
    "\n",
    "    return without_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap(dim, corr_data):\n",
    "\n",
    "    my_colors = ['black', 'lightgrey', 'white', 'red']\n",
    "    my_cmap = ListedColormap(my_colors)\n",
    "    bounds = [-1.0, -0.75, 0.75, 1.0]\n",
    "    my_norm = BoundaryNorm(bounds, ncolors=len(my_colors))\n",
    "\n",
    "\n",
    "\n",
    "    mask = np.triu(np.ones_like(corr_data))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20,20))\n",
    "    hmap = sns.heatmap(corr_data,\n",
    "                yticklabels=1, \n",
    "                ax=ax,\n",
    "                linewidths=1.0,\n",
    "                cmap=my_cmap,\n",
    "                norm=my_norm,\n",
    "                mask=mask,\n",
    "               cbar_kws = dict(use_gridspec=False,location=\"top\")\n",
    "               )\n",
    "\n",
    "    colorbar = ax.collections[0].colorbar\n",
    "    hmap.figure.savefig(f'heatmapid/{dim}_heatmap.png', format='png', dpi=150)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = initial_df.iloc[:, 12:]\n",
    "all_corr = all_df.corr(method='pearson').round(2)\n",
    "\n",
    "# save_csv('dimensions', all_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_heatmap('all_dims', all_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = get_corr_pairs(all_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-ranking",
   "metadata": {},
   "source": [
    "# eelmised, koos +1 lisamisega tunnusele\n",
    "\n",
    "['adj', 'amod'] = 0.78\n",
    "\n",
    "['discourse', 'intj'] = 1.0\n",
    "\n",
    "['intj', 'voc'] = 0.76\n",
    "\n",
    "['ccomp', 'cconj'] = 0.93\n",
    "\n",
    "['cc', 'cconj'] = 1.0\n",
    "\n",
    "['num', 'nummod'] = 0.88\n",
    "\n",
    "['coref', 'pron'] = 0.91\n",
    "\n",
    "['TTR', 'hapax_legomena'] = 0.83\n",
    "\n",
    "['2nd_prs_verb', 'imp_mood'] = 0.98\n",
    "\n",
    "['discourse', 'voc'] = 0.76\n",
    "\n",
    "['past_tense', 'pres_tense'] = -0.77\n",
    "\n",
    "['quot_mood', 'voc'] = 0.88\n",
    "\n",
    "['quot_mood', 'yneemid'] = 0.78\n",
    "\n",
    "['emoticons', 'quot_mood'] = 0.87\n",
    "\n",
    "['gen_case', 'nmod'] = 0.86\n",
    "\n",
    "['cop', 'nsubj_cop'] = 0.9\n",
    "\n",
    "['cc', 'ccomp'] = 0.93\n",
    "\n",
    "['voc', 'yneemid'] = 0.86\n",
    "\n",
    "['emoticons', 'voc'] = 0.96\n",
    "\n",
    "['emoticons', 'yneemid'] = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_df(dim_name):\n",
    "    positive = initial_df.loc[initial_df[dim_name]>=2, initial_df.columns[12:]]\n",
    "    negative = initial_df.loc[initial_df[dim_name]<2, initial_df.columns[12:]]\n",
    "    return positive, negative\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-radiation",
   "metadata": {},
   "source": [
    "## dimensioonide ja tekstide jaotumine hinnangute järgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-texas",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "originaalsed_vastused = '../dimensioonide_originaalsed_hinnangud'\n",
    "dir_list = os.listdir(originaalsed_vastused)\n",
    "\n",
    "files = [os.path.join(originaalsed_vastused, x) for x in dir_list if x.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-violation",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "for f in files:\n",
    "    with open(f, 'r') as fid:\n",
    "        print(os.path.basename(f))\n",
    "\n",
    "        csv_reader = csv.reader(fid)\n",
    "        data = [line for line in csv_reader]\n",
    "        data_df = pd.DataFrame(data).replace(r'^\\s*$', 0, regex=True)\n",
    "        summed_df = data_df.iloc[:, 1:].astype('float').sum(axis=1)/10\n",
    "        tugev, moodukas, nork, puuduv = 0, 0, 0, 0\n",
    "        for score in summed_df:\n",
    "            if score >= 3:\n",
    "                tugev += 1\n",
    "            elif score >= 2 and score < 3:\n",
    "                moodukas += 1\n",
    "            elif score >= 1 and score < 2:\n",
    "                nork += 1\n",
    "            else:\n",
    "                puuduv += 1\n",
    "        t = PrettyTable(['Hinnang ', 'Tekstide arv'])\n",
    "        t.add_row(['Tugev (hinnang = 3)', tugev])\n",
    "        t.add_row(['Mõõdukas (hinnang <3 ja >= 2)', moodukas])\n",
    "        t.add_row(['Nõrk (hinnang <2 ja >= 1)', nork])\n",
    "        t.add_row(['Puudub (ehk <1)', puuduv])\n",
    "        print(f'{t}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-rings",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dims = ['subj', 'inst', 'imp', 'arg', 'afek', 'keer', 'inter', 'form', 'abs', 'spont', 'aeg', 'info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-pantyhose",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for dim in dims:\n",
    "    print(dim)\n",
    "    df = initial_df[dim]\n",
    "    tugev, moodukas, nork, puuduv = 0, 0, 0, 0\n",
    "    # print(df)\n",
    "    for score in df:\n",
    "        if score >= 3.0:\n",
    "            tugev += 1\n",
    "        elif score >= 2 and score < 3.0:\n",
    "            moodukas += 1\n",
    "        elif score >= 1 and score < 2.0:\n",
    "            nork += 1\n",
    "        else:\n",
    "            puuduv += 1\n",
    "    t = PrettyTable(['Hinnang ', 'Tekstide arv'])\n",
    "    t.add_row(['Tugev (hinnang = 3)', tugev])\n",
    "    t.add_row(['Mõõdukas (hinnang <3 ja >= 2)', moodukas])\n",
    "    t.add_row(['Nõrk (hinnang <2 ja >= 1)', nork])\n",
    "    t.add_row(['Puudub (ehk <1)', puuduv])\n",
    "    print(f'{t}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-police",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "enormous-functionality",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ABSTRAKTNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-leader",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-ottawa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-truth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-brake",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-loading",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "abs_df = initial_df['abs']\n",
    "abs_df\n",
    "# initial_df[initial_df['abs']<=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-laser",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos, neg = make_new_df('abs')\n",
    "\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_corr = pos.corr(method='pearson').round(2)\n",
    "save_csv('abs', abs_corr)\n",
    "abs_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_heatmap('abs', abs_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = get_corr_pairs(abs_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-appointment",
   "metadata": {},
   "source": [
    "\n",
    "### NORMAALJAOTUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(dim, df1, df2, features):\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(20, 200))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        df1_mean = np.mean(df1[str(feature)])\n",
    "        df1_std = np.std(df1[str(feature)])\n",
    "        pdf1 = stats.norm.pdf(df1[str(feature)].sort_values(), df1_mean, df1_std)\n",
    "        \n",
    "        df2_mean = np.mean(df2[str(feature)])\n",
    "        df2_std = np.std(df2[str(feature)])\n",
    "        pdf2 = stats.norm.pdf(df2[str(feature)].sort_values(), df2_mean, df2_std)\n",
    "    \n",
    "        ax = plt.subplot(40, 2, i+1)\n",
    "        plt.plot(df1[str(feature)].sort_values(), pdf1, label='>=2')\n",
    "        plt.plot(df2[str(feature)].sort_values(), pdf2, label='<2')\n",
    "        plt.legend(loc=1, prop={'size': 20})\n",
    "        plt.xlabel(str(feature.upper()))\n",
    "\n",
    "#         plt.savefig(f'normdist_plots/{dim}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot('abs', pos, neg, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-tours",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-paris",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-carrier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-calibration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "collectible-employee",
   "metadata": {},
   "source": [
    "### LOGISTILINE REGRESSIOON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [*feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_abs = initial_df.loc[:, feats + ['abs']].astype('float64')\n",
    "only_abs['state'] = [1 if score >= 1 else 0 for score in only_abs['abs']]\n",
    "# print(only_abs)\n",
    "\n",
    "final_features = only_abs.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = only_abs[final_features]\n",
    "y = only_abs.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "\n",
    "plot_important_features(model, 'abstraktsus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_reg = smf.logit(\"state ~ coref + hapax_legomena + noun + nom_case + avg_word_len + past_tense + pres_tense + obl + adv + num + ade_case + nummod + part_case\", data=only_abs).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-equipment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-margin",
   "metadata": {},
   "source": [
    "# AFEKTIIVNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'afek'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, neg = make_new_df(dim)\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dim_df_corr = pos.corr(method='pearson').round(2)\n",
    "save_csv(dim, dim_df_corr)\n",
    "\n",
    "generate_heatmap(dim, dim_df_corr)\n",
    "\n",
    "\n",
    "pairs = get_corr_pairs(dim_df_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')\n",
    "\n",
    "\n",
    "generate_plot(dim, pos, neg, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-insider",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-warning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['afek']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['afek']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'afektiivsus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ avg_word_len + coref + noun + adv + pron + verbtype_ratio + TTR + punct + active_voice + adj + conj + avr_sent_len\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-factory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-ranking",
   "metadata": {},
   "source": [
    "## AEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'aeg'\n",
    "pos, neg = make_new_df(dim)\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df_corr = pos.corr(method='pearson').round(2)\n",
    "save_csv(dim, dim_df_corr)\n",
    "\n",
    "generate_heatmap(dim, dim_df_corr)\n",
    "\n",
    "pairs = get_corr_pairs(dim_df_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')\n",
    "\n",
    "\n",
    "generate_plot(dim, pos, neg, feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['aeg']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['aeg']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'aeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ coref + past_tense + pres_tense + obl + verbtype_ratio + adv + num + avg_word_len + gen_case + nummod + noun + core_verb + ade_case + propn + da_inf + cop\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-harris",
   "metadata": {},
   "source": [
    "## ARGUMENTATIIVNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'arg'\n",
    "\n",
    "pos, neg = make_new_df(dim)\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df_corr = pos.corr(method='pearson').round(2)\n",
    "save_csv(dim, dim_df_corr)\n",
    "\n",
    "generate_heatmap(dim, dim_df_corr)\n",
    "\n",
    "\n",
    "pairs = get_corr_pairs(dim_df_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')\n",
    "\n",
    "generate_plot(dim, pos, neg, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-aviation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['arg']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['arg']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'arg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ coref + hapax_legomena + propn + verbtype_ratio + past_tense + pres_tense + avg_word_len + gen_case + conj + TTR + adj + neg_polarity + obl + part_case\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-belarus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-therapist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-specific",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-comment",
   "metadata": {},
   "source": [
    "## FORMAALNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'form'\n",
    "\n",
    "pos, neg = make_new_df(dim)\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df_corr = pos.corr(method='pearson').round(2)\n",
    "save_csv(dim, dim_df_corr)\n",
    "\n",
    "generate_heatmap(dim, dim_df_corr)\n",
    "\n",
    "pairs = get_corr_pairs(dim_df_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')\n",
    "\n",
    "generate_plot(dim, pos, neg, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['form']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['form']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'formaalsus')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_reg = smf.logit(\"state ~ avg_word_len + coref + gen_case + noun + obl + adv + nmod + num\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-librarian",
   "metadata": {},
   "source": [
    "## IMPERSONAALNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'imp'\n",
    "\n",
    "pos, neg = make_new_df(dim)\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df_corr = pos.corr(method='pearson').round(2)\n",
    "save_csv(dim, dim_df_corr)\n",
    "\n",
    "generate_heatmap(dim, dim_df_corr)\n",
    "\n",
    "\n",
    "pairs = get_corr_pairs(dim_df_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')\n",
    "\n",
    "generate_plot(dim, pos, neg, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['imp']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['imp']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'impersonaalsus')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ avg_word_len + coref + noun + past_tense + pres_tense + conj + pron + num\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-uncle",
   "metadata": {},
   "source": [
    "## INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'info'\n",
    "\n",
    "pos, neg = make_new_df(dim)\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df_corr = pos.corr(method='pearson').round(2)\n",
    "save_csv(dim, dim_df_corr)\n",
    "\n",
    "generate_heatmap(dim, dim_df_corr)\n",
    "\n",
    "\n",
    "pairs = get_corr_pairs(dim_df_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')\n",
    "\n",
    "\n",
    "generate_plot(dim, pos, neg, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['info']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['info']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'info')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_reg = smf.logit(\"state ~ coref + num + avg_word_len + active_voice + propn + nummod + pron + ind_mood + hapax_legomena + nsubj\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-census",
   "metadata": {},
   "source": [
    "## INSTRUEERIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'inst'\n",
    "\n",
    "pos, neg = make_new_df(dim)\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df_corr = pos.corr(method='pearson').round(2)\n",
    "save_csv(dim, dim_df_corr)\n",
    "\n",
    "generate_heatmap(dim, dim_df_corr)\n",
    "\n",
    "\n",
    "pairs = get_corr_pairs(dim_df_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')\n",
    "\n",
    "generate_plot(dim, pos, neg, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['inst']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['inst']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'instrueerivus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ coref + pres_tense + nom_case + pron + hapax_legomena + past_tense + verbtype_ratio + noun + third_prs_verb + second_prs_verb + imp_mood + pron\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-ceremony",
   "metadata": {},
   "source": [
    "## INTERAKTIIVNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'inter'\n",
    "\n",
    "pos, neg = make_new_df(dim)\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df_corr = pos.corr(method='pearson').round(2)\n",
    "save_csv(dim, dim_df_corr)\n",
    "\n",
    "generate_heatmap(dim, dim_df_corr)\n",
    "\n",
    "\n",
    "pairs = get_corr_pairs(dim_df_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')\n",
    "\n",
    "generate_plot(dim, pos, neg, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['inter']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['inter']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'inter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ avg_word_len + hapax_legomena + TTR + gen_case + noun + verbtype_ratio + avr_sent_len\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-hopkins",
   "metadata": {},
   "source": [
    "## KEER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'keer'\n",
    "\n",
    "pos, neg = make_new_df(dim)\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df_corr = pos.corr(method='pearson').round(2)\n",
    "save_csv(dim, dim_df_corr)\n",
    "\n",
    "generate_heatmap(dim, dim_df_corr)\n",
    "\n",
    "\n",
    "pairs = get_corr_pairs(dim_df_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')\n",
    "\n",
    "\n",
    "generate_plot(dim, pos, neg, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['keer']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['keer']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'keerulisus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ avg_word_len + coref + hapax_legomena + verbtype_ratio + abbr + nmod + past_tense + obl + active_voice\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-spencer",
   "metadata": {},
   "source": [
    "## SPONT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'spont'\n",
    "\n",
    "pos, neg = make_new_df(dim)\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df_corr = pos.corr(method='pearson').round(2)\n",
    "save_csv(dim, dim_df_corr)\n",
    "\n",
    "generate_heatmap(dim, dim_df_corr)\n",
    "\n",
    "pairs = get_corr_pairs(dim_df_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')\n",
    "\n",
    "\n",
    "generate_plot(dim, pos, neg, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['spont']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['spont']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'spontaansus')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ avg_word_len + coref + noun + gen_case + nom_case + avr_sent_len + obl + propn\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-florida",
   "metadata": {},
   "source": [
    "## SUBJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'subj'\n",
    "\n",
    "pos, neg = make_new_df(dim)\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df_corr = pos.corr(method='pearson').round(2)\n",
    "save_csv(dim, dim_df_corr)\n",
    "\n",
    "generate_heatmap(dim, dim_df_corr)\n",
    "\n",
    "\n",
    "pairs = get_corr_pairs(dim_df_corr)\n",
    "for pair in pairs:\n",
    "    print(f'{pair[0]} = {pair[1]}')\n",
    "\n",
    "\n",
    "generate_plot(dim, pos, neg, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initial_df.loc[:, feats + ['subj']].astype('float64')\n",
    "df['state'] = [1 if score >= 1.5 else 0 for score in df['subj']]\n",
    "\n",
    "final_features = df.columns.values.tolist()[:-2]\n",
    "\n",
    "\n",
    "X = df[final_features]\n",
    "y = df.state\n",
    "\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plot_important_features(model, 'subjektiivsus')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = smf.logit(\"state ~ avg_word_len + coref + verbtype_ratio + adv + propn + noun\", data=df).fit()\n",
    "log_reg.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}